{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM98AaJ+GJbdAUPghcx0vAZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sean950722/hello/blob/main/EX02_01MyChatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NRuYheneZc_1"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config ={\n",
        "    \"temperature\":1,\n",
        "    \"max_output_tokens\":1280,\n",
        "}\n",
        "model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-2.0-flash\",\n",
        "    generation_config=generation_config\n",
        ")"
      ],
      "metadata": {
        "id": "ddfWg0v1OuWN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "chat = model.start_chat(history=[])\n",
        "\n",
        "while True:\n",
        "  message = input(\"You:\")\n",
        "  if message == \"bye!\":\n",
        "    break\n",
        "  response = chat.send_message(message)\n",
        "  print(\"Bot:\")\n",
        "  display(Markdown(response.text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tcXsDoPtPdwM",
        "outputId": "dd886de6-ee94-4231-cd95-70c346422ecc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You:hi\n",
            "Bot:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Hi there! How can I help you today?\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You:how ai works\n",
            "Bot:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Okay, let's break down how AI works. It's a broad field, but I'll give you a general overview and then we can dive deeper into specific areas if you'd like.\n\n**The Core Idea: Mimicking Human Intelligence**\n\nAt its heart, Artificial Intelligence aims to create machines that can perform tasks that typically require human intelligence.  This includes things like:\n\n*   **Learning:** Acquiring information and rules for using that information.\n*   **Reasoning:** Using information and rules to draw conclusions and make decisions.\n*   **Problem-solving:**  Finding solutions to complex issues.\n*   **Perception:** Understanding and interpreting sensory data (like images, sound, and text).\n*   **Natural Language Processing (NLP):** Understanding and generating human language.\n\n**Key Techniques and Components:**\n\nAI achieves these capabilities through a variety of techniques, but some of the most common and important include:\n\n1.  **Machine Learning (ML):**  This is the most popular approach right now.  Instead of being explicitly programmed with rules, ML algorithms *learn* from data.\n\n    *   **Types of Machine Learning:**\n        *   **Supervised Learning:** The algorithm is trained on a labeled dataset (i.e., data where the correct answers are known). Think of it like learning with a teacher giving you the answer key. Examples:\n            *   Image classification (identifying objects in pictures)\n            *   Spam detection (identifying spam emails)\n            *   Predicting house prices based on features like size and location.\n        *   **Unsupervised Learning:** The algorithm is trained on an unlabeled dataset and tries to find patterns and structures within the data. Think of it like exploring data without knowing what you're looking for. Examples:\n            *   Customer segmentation (grouping customers based on purchasing behavior)\n            *   Anomaly detection (identifying unusual data points)\n            *   Dimensionality reduction (simplifying complex data)\n        *   **Reinforcement Learning:** The algorithm learns by interacting with an environment and receiving rewards or penalties for its actions. Think of it like training a dog with treats. Examples:\n            *   Training game-playing AI (like AlphaGo)\n            *   Robotics control\n            *   Optimizing resource allocation\n\n2.  **Deep Learning (DL):** A subfield of ML that uses artificial neural networks with many layers (hence \"deep\").  These networks are inspired by the structure of the human brain and can learn very complex patterns.\n\n    *   **Neural Networks:**  Interconnected nodes (neurons) that process information and pass it along.  The connections between nodes have weights that are adjusted during the learning process.  Think of it like a complex network of interconnected switches that can be configured to perform different tasks.\n    *   **Convolutional Neural Networks (CNNs):**  Excellent for image and video processing.\n    *   **Recurrent Neural Networks (RNNs):**  Good for processing sequential data like text and time series.\n    *   **Transformers:** A more recent architecture that has revolutionized NLP and is also being used for other tasks.\n\n3.  **Natural Language Processing (NLP):** Focuses on enabling computers to understand, interpret, and generate human language.\n\n    *   **Key Tasks:**\n        *   **Text classification:** Categorizing text (e.g., sentiment analysis)\n        *   **Machine translation:** Translating text from one language to another\n        *   **Text summarization:** Condensing long texts into shorter summaries\n        *   **Question answering:** Answering questions based on text data\n        *   **Chatbots:** Conversational AI systems\n\n4.  **Expert Systems:**  These systems use a knowledge base of facts and rules to solve problems in a specific domain. They are often used for diagnosis, decision support, and planning.  While less common than machine learning these days, they still have applications.\n\n5.  **Rule-Based Systems:**  Systems that use a set of predefined rules to make decisions. These systems are often used for tasks that require logical reasoning and decision-making.\n\n**The Learning Process (Simplified):**\n\n1.  **Data Collection:**  Gathering a large dataset relevant to the task.  The quality and quantity of data are crucial.\n2.  **Data Preprocessing:**  Cleaning and preparing the data for training.  This might involve removing errors, handling missing values, and transforming the data into a suitable format.\n3.  **Model Selection:**  Choosing an appropriate AI model (e.g., a specific type of neural network or machine learning algorithm) based on the task and the data.\n4.  **Training:**  Feeding the preprocessed data to the model and allowing it to learn the patterns and relationships within the data.  This involves adjusting the model's parameters to minimize errors.\n5.  **Evaluation:**  Testing the trained model on a separate dataset to assess its performance and generalization ability.\n6.  **Deployment:**  Integrating the trained model into a real-world application.\n7.  **Monitoring and Retraining:** Continuously monitoring the model's performance and retraining it with new data to maintain its accuracy and relevance.\n\n**Tools and Technologies:**\n\n*   **Programming Languages:** Python (most popular), R, Java, C++\n*   **Libraries and Frameworks:** TensorFlow, PyTorch, scikit-learn, Keras\n*   **Cloud Platforms:** Amazon Web Services (AWS), Google Cloud Platform (GCP), Microsoft Azure\n\n**Example: Image Recognition (using Deep Learning):**\n\n1.  **Data:** A massive dataset of labeled images (e.g., images of cats, dogs, cars, etc.).\n2.  **Model:** A Convolutional Neural Network (CNN).\n3.  **Training:** The CNN is fed the images, and it learns to identify features like edges, textures, and shapes that are characteristic of different objects. The network adjusts its internal parameters to minimize the error in its predictions.\n4.  **Evaluation:** The trained CNN is"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You:bye!\n"
          ]
        }
      ]
    }
  ]
}